{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27916a12-0f43-418a-b4b0-802a38824bd7",
   "metadata": {},
   "source": [
    "### Author info : Vaishnav Krishna P\n",
    "#### dataset url : https://www.kaggle.com/datasets/julian3833/jigsaw-toxic-comment-classification-challenge?select=train.csv\n",
    "- Dataset is taken from the kaggle website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cd60070e-9d8e-4764-a058-0f81c628e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessory libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5e981a86-1112-49a4-a8c4-2bf74b9a5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset \n",
    "dataset = pd.read_csv('../Dataset/train.csv')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "38c40a4b-dc12-482a-81d4-d83482360359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 records \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5051b21b-1f4d-42d5-bee0-29be6f1cf5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the dataset \n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "89305dff-03da-40e3-bcbd-11339b419bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             100 non-null    object\n",
      " 1   comment_text   100 non-null    object\n",
      " 2   toxic          100 non-null    int64 \n",
      " 3   severe_toxic   100 non-null    int64 \n",
      " 4   obscene        100 non-null    int64 \n",
      " 5   threat         100 non-null    int64 \n",
      " 6   insult         100 non-null    int64 \n",
      " 7   identity_hate  100 non-null    int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# description of the dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3593126b-ffb7-4d95-81e4-4747d2622f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text5: \"\n",
      "\n",
      "Congratulations from me as well, use the tools well.  · talk \"\n",
      "\n",
      "\n",
      "Text6: COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "\n",
      "\n",
      "Text7: Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.\n",
      "\n",
      "\n",
      "Text8: Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169\n",
      "\n",
      "\n",
      "Text9: alignment on this subject and which are contrary to those of DuLithgow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets print some of the text's \n",
    "for i in range(5,10):\n",
    "    print(f\"\\nText{i}: {dataset.iloc[i,1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c5d7e2-2c93-413b-a177-df9b76b334f5",
   "metadata": {},
   "source": [
    "### TEXT CLEANING\n",
    "1. Lowering Case\n",
    "2. Remove numbers, punctuations and special charectors\n",
    "3. stopword removal\n",
    "4. spellcorrection\n",
    "5. tokenization\n",
    "6. Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d6fe7fa3-86d7-43bc-902d-6df363d24307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this is a devil's house\""
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowering the case \n",
    "text = \"This is a devil's House\"\n",
    "\n",
    "# lower case \n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4d8a6ffb-e4c9-4f0a-a234-86818d42667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello this  may\n"
     ]
    }
   ],
   "source": [
    "# Removal of numbers and special charectors \n",
    "text = \"12345hello.:'? this ()&45 May.\"\n",
    "\n",
    "import re\n",
    "text = re.sub(r'[^a-z\\s]', \"\",text.lower())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9bdf85f1-eca4-4c9f-9383-5ad082c5c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto spelling correction\n",
    "from autocorrect import Speller \n",
    "\n",
    "speller = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6538c361-df86-45f2-8e6f-e1dff01bee72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'misleading'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speller('misleding') # correct : misleading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b17201e1-f636-4040-a31c-4730e12bcac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"this is a final day of the collage\"\n",
    "tokenized_words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a74aed58-5dcb-4986-aa26-8cf767d2541b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'final', 'day', 'of', 'the', 'collage']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_words # tokenized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "76c1e7e6-7307-4f24-8ff8-e74d4ff36c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stop words\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "effebb0f-b545-430b-90e3-9c0ebc0186d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords \n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1ce875dc-11ae-40c2-b40e-74a0ff2a5945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:10] # sample stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "dd2de879-52ff-47b2-a721-01d00fa5e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocessing the text \n",
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from autocorrect import Speller\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# speller object \n",
    "speller = Speller(lang='en')\n",
    "\n",
    "# lematization object \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_cleaning(text):\n",
    "    # converting to lower case \n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing all numbers, punctuation marks , and all the irrelavant symbols etx\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    # apply the word tokenization\n",
    "    word_tokens = word_tokenize(text)\n",
    "\n",
    "    # applying for the text correction\n",
    "    word_tokens = [speller(word) for word in word_tokens]\n",
    "\n",
    "    # removing the stop words\n",
    "    clean_tokens = [word for word in word_tokens if word not in stopwords.words(\"english\")]\n",
    "\n",
    "    # applying the Lematization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "\n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "222a4186-6d7c-4d33-b54b-c71b2caaa2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please call'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the function \n",
    "text_cleaning(\"please call me @ 854345678\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "486caf30-b4ac-494e-8644-dafea8421e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"clean_text\"] = dataset['comment_text'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9cc7b341-87f2-4d66-9c59-8d080a4f6d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orginal text : Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "\n",
      "Clean Text: explanation edits made username hardcore metallica fan reverted vandalism closure gas voted new york doll fac please dont remove template talk page since im retired\n",
      "\n",
      "\n",
      "Orginal text : D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "\n",
      "Clean Text: dawn match background colour im seemingly stuck thanks talk january utc\n",
      "\n",
      "\n",
      "Orginal text : Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "\n",
      "Clean Text: hey man im really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info\n",
      "\n",
      "\n",
      "Orginal text : \"\n",
      "More\n",
      "I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\n",
      "\n",
      "There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"\n",
      "\n",
      "Clean Text: cant make real suggestion improvement wondered section statistic later subsection type accident think reference may need tidying exact format ie date format etc later noone else first preference formatting style reference want please let know appears backlog article review guess may delay reviewer turn listed relevant form eg wikipediagoodarticlenominationstransport\n",
      "\n",
      "\n",
      "Orginal text : You, sir, are my hero. Any chance you remember what page that's on?\n",
      "\n",
      "Clean Text: sir hero chance remember page thats\n",
      "\n",
      "\n",
      "Orginal text : \"\n",
      "\n",
      "Congratulations from me as well, use the tools well.  · talk \"\n",
      "\n",
      "Clean Text: congratulation well use tool well talk\n",
      "\n",
      "\n",
      "Orginal text : COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "\n",
      "Clean Text: cocksucker piss around work\n",
      "\n",
      "\n",
      "Orginal text : Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.\n",
      "\n",
      "Clean Text: vandalism matt shirvington article reverted please dont banned\n",
      "\n",
      "\n",
      "Orginal text : Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169\n",
      "\n",
      "Clean Text: sorry word nonsense offensive anyway im intending write anything articleshow would jump vandalism im merely requesting encyclopedic one use school reference selective breeding page almost stub point animal breeding short messy article give info must someone around expertise eugenics\n",
      "\n",
      "\n",
      "Orginal text : alignment on this subject and which are contrary to those of DuLithgow\n",
      "\n",
      "Clean Text: alignment subject contrary dulithgow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"\\nOrginal text : {dataset['comment_text'].iloc[i]}\\n\\nClean Text: {dataset['clean_text'].iloc[i]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
